{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_Image_Data_Preparation","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XzPg64OS68GH","colab_type":"text"},"source":["#Image Data Preparation\n","\n","**Objective:** This exercise explores on the Keras library's role in computer vision. It shows how to load and convert images with Keras, how to use the MNIST handwritten image classification dataset and how to employ the ImageDataGenerator class."]},{"cell_type":"markdown","metadata":{"id":"4hTR4-zq7quj","colab_type":"text"},"source":["Getting our dataset"]},{"cell_type":"code","metadata":{"id":"K4BfzSBhxrno","colab_type":"code","colab":{}},"source":["# clone github repo\n","!git clone https://github.com/zaka-ai/computer-vision-course.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oSeXPT00x5fg","colab_type":"text"},"source":["## How to Load an Image with Keras\n","\n","Keras provides the `load_img()` function for loading an image from file as a PIL image object. The example below loads the Bondi Beach photograph from file as a PIL image and reports details about the loaded image."]},{"cell_type":"code","metadata":{"id":"Lpdk60JCx6Kg","colab_type":"code","colab":{}},"source":["# example of loading an image with the Keras API\n","from tensorflow.keras.preprocessing.image import load_img\n","\n","# load the image\n","img_path = \"computer-vision-course/deep_learning/data/image1.jpg\"\n","img = load_img(img_path)\n","\n","# report details about the image\n","print(type(img))\n","print(img.format)\n","print(img.mode)\n","print(img.size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nUFT5m4Uy4lD","colab_type":"text"},"source":["## How to Convert an Image With Keras\n","\n","Keras provides the `img_to_array()` function for converting a loaded image in PIL format into a NumPy array for use with deep learning models. The API also provides the `array_to_img()` function that can be used for converting a NumPy array of pixel data into a PIL image. This can be useful if the pixel data is modified in array format because it can be saved or viewed. The example below loads the test image, converts it to a NumPy array, and then converts it back into a PIL image."]},{"cell_type":"code","metadata":{"id":"VMCkviX-y453","colab_type":"code","colab":{}},"source":["# example of converting an image with the Keras API\n","from tensorflow.keras.preprocessing.image import load_img \n","from tensorflow.keras.preprocessing.image import img_to_array \n","from tensorflow.keras.preprocessing.image import array_to_img\n","\n","# load the image\n","img_path = \"computer-vision-course/deep_learning/data/image1.jpg\"\n","img = load_img(img_path)\n","print(type(img))\n","\n","# convert to numpy array\n","img_array = img_to_array(img) \n","print(img_array.dtype)\n","print(img_array.shape)\n","\n","# convert back to image\n","img_pil = array_to_img(img_array)\n","print(type(img))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vWa5Q0jg1Cnt","colab_type":"text"},"source":["## ImageDataGenerator Class"]},{"cell_type":"markdown","metadata":{"id":"IBDZq60S74pM","colab_type":"text"},"source":["### MNIST Handwritten Image Classification Dataset"]},{"cell_type":"code","metadata":{"id":"Spw_JyDG1GHa","colab_type":"code","colab":{}},"source":["from tensorflow.keras.datasets import mnist\n","\n","(trainX, trainY), (testX, testY) = mnist.load_data()\n","\n","# summarize dataset shape\n","print(\"Train\", trainX.shape, trainY.shape)\n","print(\"Test\", testX.shape, testY.shape)\n","\n","# summarize pixel values\n","print(\"Train\", trainX.min(), trainX.max(), trainX.mean(), trainX.std())\n","print(\"Test\", testX.min(), testX.max(), testX.mean(), testX.std())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OpWYm9_m2o2x","colab_type":"text"},"source":["### How to Normalize Images With ImageDataGenerator\n","\n","**Reshape dataset:** the MNIST dataset is loaded with number of samples, number of pixels in width and height but not number of channels. This is why we make sure that the ImageDataGenerator class and Keras functions receive datasets having the number of samples, the size and the depth all together."]},{"cell_type":"code","metadata":{"id":"xBappxlP2qBV","colab_type":"code","colab":{}},"source":["# reshape dataset to have a single channel\n","\n","# trainX: (60000, 28, 28) => (60000, 28, 28, 1)\n","# testX:  (10000, 28, 28) => (10000, 28, 28, 1)\n","\n","trainX = trainX.reshape((trainX.shape[0], trainX.shape[1], trainX.shape[2], 1))\n","testX = testX.reshape((testX.shape[0], trainX.shape[1], trainX.shape[2], 1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4s-8ZZPQDobF","colab_type":"text"},"source":["**Rescale:** Normalize all the pixel values of the dataset to an interval of 0 to 1 instead of having small weight values when training deep learning networks for example and very large pixel values by comparison."]},{"cell_type":"code","metadata":{"id":"Q_xCMpdjDpgu","colab_type":"code","colab":{}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# confirm scale of pixels\n","print('Train min=%.3f, max=%.3f' % (trainX.min(), trainX.max()))\n","print('Test min=%.3f, max=%.3f' % (testX.min(), testX.max()))\n","\n","# create generator (1.0/255.0)\n","datagen = ImageDataGenerator(rescale=1.0/255.0)\n","\n","# prepare a iterators to scale images\n","train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n","test_iterator = datagen.flow(testX, testY, batch_size=64)\n","\n","# 60000 / 64 = 937.5 ~= 938\n","\n","print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n","\n","# confirm the scaling works\n","batchX, batchy = train_iterator.next()\n","print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0d5Yki093nEE","colab_type":"text"},"source":["### How to Center Images With ImageDataGenerator\n","**Center pixel values:** Find the mean of the pixel values and make sure all the pixels are distributed around it as if it were the new zero and the remaining values are positive and negative.\n"]},{"cell_type":"code","metadata":{"id":"JZly7t0W3pn9","colab_type":"code","colab":{}},"source":["# report per-image mean\n","print('Means train=%.3f, test=%.3f' % (trainX.mean(), testX.mean()))\n","\n","# create generator that centers pixel values\n","datagen = ImageDataGenerator(featurewise_center=True)\n","\n","# calculate the mean on the training dataset\n","datagen.fit(trainX)\n","print('Data Generator Mean: %.3f' % datagen.mean)\n","\n","# demonstrate effect on a single batch of samples\n","iterator = datagen.flow(trainX, trainY, batch_size=64)\n","\n","# get a batch\n","batchX, batchy = iterator.next()\n","\n","# mean pixel value in the batch\n","print(batchX.shape, batchX.mean())\n","\n","# demonstrate effect on entire training dataset\n","iterator = datagen.flow(trainX, trainY, batch_size=len(trainX), shuffle=False)\n","\n","# get a batch\n","batchX, batchy = iterator.next()\n","\n","# mean pixel value in the batch\n","print(batchX.shape, batchX.mean())\n","\n","#display an image\n","img2 = batchX[41]\n","print(img2.shape)\n","from google.colab.patches import cv2_imshow\n","cv2_imshow(img2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wI0bIHsZ9UQB","colab_type":"text"},"source":["## TASK: Load dataset images progressively\n","In this task, we will code a Keras API set of instructions to progressively load data from disk."]},{"cell_type":"code","metadata":{"id":"Ba-SE6oU9YXA","colab_type":"code","colab":{}},"source":["# FILL BLANKS"],"execution_count":null,"outputs":[]}]}
